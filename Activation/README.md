
Activation functions are key players in artificial neural networks (ANNs). 
They determine whether a neuron should be activated or not by transforming 
the weighted sum of inputs into an output signal for the next layer.

Common examples include the sigmoid, hyperbolic tangent (tanh), and rectified linear unit (ReLU) functions.
